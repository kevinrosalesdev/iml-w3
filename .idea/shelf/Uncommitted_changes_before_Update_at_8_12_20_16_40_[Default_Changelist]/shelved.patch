Index: src/arffdatasetreader/dataset_reader.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from builtins import int\n\nfrom scipy.io import arff\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\n\n\ndef process_dataset(dataset_type: str, fold_index: int) -> (np.ndarray, np.ndarray):\n    accepted_ds_types = ['numerical', 'mixed']\n    if dataset_type not in accepted_ds_types:\n        raise ValueError(f\"{dataset_type}:: not valid dataset type\")\n    if fold_index not in range(0, 10):\n        raise ValueError(f\"{dataset_type}:: not valid fold index\")\n\n    print(\"Reading dataset: \" + dataset_type)\n    if dataset_type == 'numerical':\n        num_ds_path = \"datasets/pen-based/pen-based\"\n        return process_num_data(num_ds_path, fold_index)\n\n    if dataset_type == 'mixed':\n        mix_ds_path = \"datasets/hypothyroid/hypothyroid\"\n        return process_mix_data(mix_ds_path, fold_index)\n\n\ndef process_num_data(path: str, fold_index: int) -> (np.ndarray, np.ndarray):\n    print(f\"Processing Numerical Train and Test fold n째{fold_index}...\")\n\n    numerical_train_df, numerical_test_df = from_arff_to_pandas_dataframe(fold_index, path)\n    numerical_test_df.drop(numerical_test_df.iloc[:, -1:], axis=1, inplace=True)\n    apply_decoding(numerical_train_df)\n    print(\"Numerical matrices created.\")\n    return numerical_train_df.to_numpy(), numerical_test_df.to_numpy()\n\n\ndef process_mix_data(path: str, fold_index: int) -> (np.ndarray, np.ndarray):\n    print(f\"Processing Mixed Train and Test fold n째{fold_index}...\")\n\n    mixed_train_df, mixed_test_df = from_arff_to_pandas_dataframe(fold_index, path)\n    mixed_test_df.drop(mixed_test_df.iloc[:, -1:], axis=1, inplace=True)\n\n    apply_decoding(mixed_train_df)\n    apply_decoding(mixed_test_df)\n\n    # Saving train class column\n    train_class_column = mixed_train_df[\"Class\"]\n    mixed_train_df.drop(mixed_train_df.iloc[:, -1:], axis=1, inplace=True)\n\n    mixed_train_cleaned = dealing_with_missing_values(mixed_train_df)\n    mixed_test_cleaned = dealing_with_missing_values(mixed_test_df)\n\n    # Label encoding for binary columns\n    columns_label_encoding = ['sex', 'on_thyroxine', 'query_on_thyroxine',\n                              'on_antithyroid_medication', 'sick', 'pregnant', 'thyroid_surgery',\n                              'I131_treatment', 'query_hypothyroid', 'query_hyperthyroid', 'lithium',\n                              'goitre', 'tumor', 'hypopituitary', 'psych', 'TSH_measured',\n                              'T3_measured', 'TT4_measured', 'T4U_measured',\n                              'FTI_measured']\n\n    apply_label_encoding(mixed_train_cleaned, columns_label_encoding)\n    apply_label_encoding(mixed_test_cleaned, columns_label_encoding)\n\n    # One hot encoding for the last one 'referral source'\n    mixed_train_encoded = pd.get_dummies(mixed_train_cleaned)\n    mixed_test_encoded = pd.get_dummies(mixed_test_cleaned)\n\n    mixed_train_normalized = apply_normalization(mixed_train_encoded)\n    mixed_test_normalized = apply_normalization(mixed_test_encoded)\n\n    # Merging train class column to the rest of the processed train columns\n    mixed_train_normalized[\"Class\"] = train_class_column\n\n    print(\"Mixed matrices created.\")\n    return mixed_train_normalized.to_numpy(), mixed_test_normalized.to_numpy()\n\n\ndef from_arff_to_pandas_dataframe(fold_index, path):\n    train_dataset, train_meta = arff.loadarff(f\"{path}.fold.00000{fold_index}.train.arff\")\n    test_dataset, test_meta = arff.loadarff(f\"{path}.fold.00000{fold_index}.test.arff\")\n    train_df = pd.DataFrame(train_dataset)\n    test_df = pd.DataFrame(test_dataset)\n    return train_df, test_df\n\n\ndef apply_normalization(pandas_dataframe):\n    # Normalizing to 0, 1\n    sc = MinMaxScaler(feature_range=(0, 1))\n    values_normalized = sc.fit_transform(pandas_dataframe)\n    return pd.DataFrame(values_normalized, columns=pandas_dataframe.columns)\n\n\ndef apply_label_encoding(pandas_dataframe, columns):\n    # Label Encoding\n    for column in columns:\n        le = LabelEncoder()\n        pandas_dataframe[column] = le.fit_transform(pandas_dataframe[column])\n\n\ndef apply_decoding(pandas_dataframe):\n    # Decoding the dataset, these strings are in the form u'string_value'\n    for column in pandas_dataframe:\n        if pandas_dataframe[column].dtype == object:\n            pandas_dataframe[column] = pandas_dataframe[column].str.decode('utf8')\n\n\ndef dealing_with_missing_values(mixed_df):\n    # Dropping column with all missing values (3772 of 6064)\n    mixed_df.drop('TBG', axis=1, inplace=True)\n    # Dropping column with just one distinct value\n    mixed_df.drop('TBG_measured', axis=1, inplace=True)\n    # Converting Unknown char from \"?\" to NaN and eliminate the corresponding rows\n    mixed_df.replace('?', np.nan, inplace=True)\n    # Dealing with missing values in continuous columns replacing them with the median value of each column\n    # (the distribution of this column has very high std)\n    columns_cont_with_missing_values = ['age', 'TSH', 'T3', 'TT4', 'T4U', 'FTI']\n    for column_of_missing_values in columns_cont_with_missing_values:\n        mixed_df[column_of_missing_values].fillna(mixed_df[column_of_missing_values].median(), inplace=True)\n    mixed_df['sex'].fillna(mixed_df['sex'].value_counts().index[0], inplace=True)\n    return mixed_df\n\n\ndef print_count_values_per_column(df: pd.DataFrame, columns: list, show_description: bool = False):\n    for column in columns:\n        print(\"-------------------------\")\n        print(f\"*{column}*\")\n        print(\"-------------------------\")\n        print(df[column].value_counts())\n        if show_description:\n            print(\"******************\")\n            print(df[column].describe())\n            print(\"******************\")\n\n\ndef get_ten_fold_preprocessed_dataset(dataset_type: str) -> (np.ndarray, np.ndarray):\n    accepted_ds_types = ['numerical', 'mixed']\n    if dataset_type not in accepted_ds_types:\n        raise ValueError(f\"{dataset_type}:: not valid dataset type\")\n    train_matrices = []\n    test_matrices = []\n    for fold_index in range(0, 10):\n        train_matrix, test_matrix = process_dataset(dataset_type, fold_index)\n        train_matrices.append(train_matrix)\n        test_matrices.append(test_matrix)\n    return train_matrices, test_matrices\n\n\ndef get_datasets() -> np.ndarray:\n    num_train_matrices, num_test_matrices = get_ten_fold_preprocessed_dataset(dataset_type='numerical')\n    mix_train_matrices, mix_test_matrices = get_ten_fold_preprocessed_dataset(dataset_type='mixed')\n    return [(num_train_matrices, num_test_matrices),\n            (mix_train_matrices, mix_test_matrices)]\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/arffdatasetreader/dataset_reader.py b/src/arffdatasetreader/dataset_reader.py
--- a/src/arffdatasetreader/dataset_reader.py	(revision aa956a756c4951ce7e0eac4957fe91cdd4b029cc)
+++ b/src/arffdatasetreader/dataset_reader.py	(date 1607131307222)
@@ -7,7 +7,7 @@
 from sklearn.preprocessing import MinMaxScaler
 
 
-def process_dataset(dataset_type: str, fold_index: int) -> (np.ndarray, np.ndarray):
+def process_dataset(dataset_type: str, fold_index: int, get_test_labels=False) -> (np.ndarray, np.ndarray):
     accepted_ds_types = ['numerical', 'mixed']
     if dataset_type not in accepted_ds_types:
         raise ValueError(f"{dataset_type}:: not valid dataset type")
@@ -17,28 +17,32 @@
     print("Reading dataset: " + dataset_type)
     if dataset_type == 'numerical':
         num_ds_path = "datasets/pen-based/pen-based"
-        return process_num_data(num_ds_path, fold_index)
+        return process_num_data(num_ds_path, fold_index, get_test_labels)
 
     if dataset_type == 'mixed':
         mix_ds_path = "datasets/hypothyroid/hypothyroid"
-        return process_mix_data(mix_ds_path, fold_index)
+        return process_mix_data(mix_ds_path, fold_index, get_test_labels)
 
 
-def process_num_data(path: str, fold_index: int) -> (np.ndarray, np.ndarray):
+def process_num_data(path: str, fold_index: int, get_test_labels: bool) -> (np.ndarray, np.ndarray):
     print(f"Processing Numerical Train and Test fold n째{fold_index}...")
 
     numerical_train_df, numerical_test_df = from_arff_to_pandas_dataframe(fold_index, path)
-    numerical_test_df.drop(numerical_test_df.iloc[:, -1:], axis=1, inplace=True)
+    if not get_test_labels:
+        numerical_test_df.drop(numerical_test_df.iloc[:, -1:], axis=1, inplace=True)
+
     apply_decoding(numerical_train_df)
+    apply_decoding(numerical_test_df)
     print("Numerical matrices created.")
     return numerical_train_df.to_numpy(), numerical_test_df.to_numpy()
 
 
-def process_mix_data(path: str, fold_index: int) -> (np.ndarray, np.ndarray):
+def process_mix_data(path: str, fold_index: int, get_test_labels: bool) -> (np.ndarray, np.ndarray):
     print(f"Processing Mixed Train and Test fold n째{fold_index}...")
 
     mixed_train_df, mixed_test_df = from_arff_to_pandas_dataframe(fold_index, path)
-    mixed_test_df.drop(mixed_test_df.iloc[:, -1:], axis=1, inplace=True)
+    if not get_test_labels:
+        mixed_test_df.drop(mixed_test_df.iloc[:, -1:], axis=1, inplace=True)
 
     apply_decoding(mixed_train_df)
     apply_decoding(mixed_test_df)
